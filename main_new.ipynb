{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0d54a9dce5f342439f9f29bdec8af974",
            "f40d7a1c4c5d430e9070ef9c3a356c19",
            "a2a5ed36e8c64e37a14c8898c02a2235",
            "0f244e19e3d643e09880d3facb11609e",
            "2a5485dc811c4cb3a5f26ca8333d07f7",
            "aa11a4d2fa0640f3879dd1852bddf4ef",
            "d36b556aba1e48ccb865785d0cafcf57",
            "783c4a2068184bc9b1e51bcf8b5738d2",
            "abef25ba988a4ea690f214727efe917d",
            "5e30e0195bbb48ed8be66d504a2d259f",
            "5fdf2cb8df8c4b7c8a3fc4d23b206ce3"
          ]
        },
        "id": "Y0sMhQTQNpF2",
        "outputId": "bc651270-d7cf-45b8-9615-37e4bac6ea75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Original shape: (11000, 7)\n",
            "Columns: ['requirement_text', 'primary_service', 'service_category', 'complexity_level', 'deployment_scenario', 'keywords_extracted', 'reference_url']\n",
            "\n",
            "Service â†’ Category map (sample):\n",
            "  Amazon VPC  -->  Networking\n",
            "  Amazon EFS  -->  Storage\n",
            "  Amazon CloudFront  -->  Networking\n",
            "  AWS Backup  -->  Storage\n",
            "  Amazon ElastiCache  -->  Database\n",
            "  Amazon Aurora  -->  Database\n",
            "  AWS Fargate  -->  Compute\n",
            "  AWS WAF  -->  Security\n",
            "  Elastic Load Balancing  -->  Networking\n",
            "  Amazon DynamoDB  -->  Database\n",
            "\n",
            "After cleaning: (11000, 2)\n",
            "After preprocessing: (11000, 3)\n",
            "Number of classes: 20\n",
            "Classes (sample): ['AWS Backup', 'AWS Fargate', 'AWS IAM', 'AWS KMS', 'AWS Lambda', 'AWS Secrets Manager', 'AWS WAF', 'Amazon Aurora', 'Amazon CloudFront', 'Amazon DynamoDB'] ...\n",
            "Train size: 7700\n",
            "Val size: 1650\n",
            "Test size: 1650\n",
            "TF-IDF shapes: (7700, 2134) (1650, 2134) (1650, 2134)\n",
            "\n",
            "Training ML model: LinearSVC\n",
            "LinearSVC Val Accuracy: 1.0000\n",
            "LinearSVC Val F1-score: 1.0000\n",
            "--------------------------------------------------\n",
            "\n",
            "Training ML model: LogisticRegression\n",
            "LogisticRegression Val Accuracy: 1.0000\n",
            "LogisticRegression Val F1-score: 1.0000\n",
            "--------------------------------------------------\n",
            "\n",
            "Training ML model: MultinomialNB\n",
            "MultinomialNB Val Accuracy: 1.0000\n",
            "MultinomialNB Val F1-score: 1.0000\n",
            "--------------------------------------------------\n",
            "\n",
            "Training ML model: RandomForest\n",
            "RandomForest Val Accuracy: 0.9976\n",
            "RandomForest Val F1-score: 0.9976\n",
            "--------------------------------------------------\n",
            "\n",
            "Training ML model: KNN\n",
            "KNN Val Accuracy: 1.0000\n",
            "KNN Val F1-score: 1.0000\n",
            "--------------------------------------------------\n",
            "\n",
            "ML validation leaderboard:\n",
            "                     Accuracy        F1\n",
            "LinearSVC           1.000000  1.000000\n",
            "LogisticRegression  1.000000  1.000000\n",
            "MultinomialNB       1.000000  1.000000\n",
            "KNN                 1.000000  1.000000\n",
            "RandomForest        0.997576  0.997572\n",
            "\n",
            "Best ML model (val): LinearSVC\n",
            "Saved: best_aws_classifier.pkl, tfidf_vectorizer.pkl, label_encoder.pkl\n",
            "\n",
            "=== Best ML Model Test Performance ===\n",
            "Accuracy: 1.0\n",
            "Weighted F1: 1.0\n",
            "\n",
            "Classification Report (ML):\n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            AWS Backup       1.00      1.00      1.00        91\n",
            "           AWS Fargate       1.00      1.00      1.00        81\n",
            "               AWS IAM       1.00      1.00      1.00        90\n",
            "               AWS KMS       1.00      1.00      1.00        76\n",
            "            AWS Lambda       1.00      1.00      1.00        89\n",
            "   AWS Secrets Manager       1.00      1.00      1.00        83\n",
            "               AWS WAF       1.00      1.00      1.00        77\n",
            "         Amazon Aurora       1.00      1.00      1.00        79\n",
            "     Amazon CloudFront       1.00      1.00      1.00        78\n",
            "       Amazon DynamoDB       1.00      1.00      1.00        81\n",
            "            Amazon EBS       1.00      1.00      1.00        84\n",
            "            Amazon EC2       1.00      1.00      1.00        81\n",
            "            Amazon EFS       1.00      1.00      1.00        79\n",
            "    Amazon ElastiCache       1.00      1.00      1.00        81\n",
            "            Amazon RDS       1.00      1.00      1.00        80\n",
            "       Amazon Route 53       1.00      1.00      1.00        87\n",
            "             Amazon S3       1.00      1.00      1.00        80\n",
            "            Amazon VPC       1.00      1.00      1.00        84\n",
            "     Elastic Beanstalk       1.00      1.00      1.00        79\n",
            "Elastic Load Balancing       1.00      1.00      1.00        90\n",
            "\n",
            "              accuracy                           1.00      1650\n",
            "             macro avg       1.00      1.00      1.00      1650\n",
            "          weighted avg       1.00      1.00      1.00      1650\n",
            "\n",
            "\n",
            "BERT Train size: (9913, 3)\n",
            "BERT Val size: (3726, 3)\n",
            "BERT Test size: (3747, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d54a9dce5f342439f9f29bdec8af974"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Epoch 1/5 =====\n",
            "Epoch 1 Train Loss: 1.1230 | Train Acc: 0.7889\n",
            "Val Loss: 0.0372 | Val Acc: 1.0000 | Val F1: 1.0000\n",
            "New best DistilBERT model, saving checkpoint...\n",
            "\n",
            "===== Epoch 2/5 =====\n",
            "Epoch 2 Train Loss: 0.0269 | Train Acc: 1.0000\n",
            "Val Loss: 0.0093 | Val Acc: 1.0000 | Val F1: 1.0000\n",
            "\n",
            "===== Epoch 3/5 =====\n",
            "Epoch 3 Train Loss: 0.0102 | Train Acc: 1.0000\n",
            "Val Loss: 0.0048 | Val Acc: 1.0000 | Val F1: 1.0000\n",
            "\n",
            "===== Epoch 4/5 =====\n",
            "Epoch 4 Train Loss: 0.0062 | Train Acc: 1.0000\n",
            "Val Loss: 0.0033 | Val Acc: 1.0000 | Val F1: 1.0000\n",
            "\n",
            "===== Epoch 5/5 =====\n",
            "Epoch 5 Train Loss: 0.0048 | Train Acc: 1.0000\n",
            "Val Loss: 0.0029 | Val Acc: 1.0000 | Val F1: 1.0000\n",
            "\n",
            "=== DistilBERT Test Performance ===\n",
            "Accuracy: 1.0\n",
            "Weighted F1: 1.0\n",
            "\n",
            "Classification Report (DistilBERT):\n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "            AWS Backup       1.00      1.00      1.00       214\n",
            "           AWS Fargate       1.00      1.00      1.00       173\n",
            "               AWS IAM       1.00      1.00      1.00       201\n",
            "               AWS KMS       1.00      1.00      1.00       164\n",
            "            AWS Lambda       1.00      1.00      1.00       222\n",
            "   AWS Secrets Manager       1.00      1.00      1.00       188\n",
            "               AWS WAF       1.00      1.00      1.00       175\n",
            "         Amazon Aurora       1.00      1.00      1.00       175\n",
            "     Amazon CloudFront       1.00      1.00      1.00       157\n",
            "       Amazon DynamoDB       1.00      1.00      1.00       196\n",
            "            Amazon EBS       1.00      1.00      1.00       177\n",
            "            Amazon EC2       1.00      1.00      1.00       207\n",
            "            Amazon EFS       1.00      1.00      1.00       162\n",
            "    Amazon ElastiCache       1.00      1.00      1.00       174\n",
            "            Amazon RDS       1.00      1.00      1.00       190\n",
            "       Amazon Route 53       1.00      1.00      1.00       203\n",
            "             Amazon S3       1.00      1.00      1.00       188\n",
            "            Amazon VPC       1.00      1.00      1.00       189\n",
            "     Elastic Beanstalk       1.00      1.00      1.00       184\n",
            "Elastic Load Balancing       1.00      1.00      1.00       208\n",
            "\n",
            "              accuracy                           1.00      3747\n",
            "             macro avg       1.00      1.00      1.00      3747\n",
            "          weighted avg       1.00      1.00      1.00      3747\n",
            "\n",
            "\n",
            "================ AWS ARCHITECTURAL RECOMMENDER â€” INTERACTIVE MODE ================\n",
            "Type your AWS requirement below. Type 'exit' to stop.\n",
            "\n",
            "Your Query: protestion againd malicious websites\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: protestion againd malicious websites\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. AWS WAF  | Category: Security  | Score: 0.547\n",
            "  2. AWS IAM  | Category: Security  | Score: 0.043\n",
            "  3. Amazon CloudFront  | Category: Networking  | Score: 0.043\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n",
            "Your choice [1-3 or Enter]: 1\n",
            "\n",
            "âœ… You selected option 1.\n",
            "=============== FINAL RECOMMENDATION ===============\n",
            "ðŸ·ï¸  AWS Service: AWS WAF\n",
            "ðŸ“‚ Category: Security\n",
            "ðŸ“Š Confidence Score (model space): 0.547\n",
            "ðŸ¤– Model Source: DistilBERT\n",
            "====================================================\n",
            "\n",
            "Your Query: deploymnet pipelines\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: deploymnet pipelines\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. AWS Fargate  | Category: Compute  | Score: 0.263\n",
            "  2. Amazon VPC  | Category: Networking  | Score: 0.135\n",
            "  3. Amazon Route 53  | Category: Networking  | Score: 0.067\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n",
            "Your choice [1-3 or Enter]: 1\n",
            "\n",
            "âœ… You selected option 1.\n",
            "=============== FINAL RECOMMENDATION ===============\n",
            "ðŸ·ï¸  AWS Service: AWS Fargate\n",
            "ðŸ“‚ Category: Compute\n",
            "ðŸ“Š Confidence Score (model space): 0.263\n",
            "ðŸ¤– Model Source: DistilBERT\n",
            "====================================================\n",
            "\n",
            "Your Query: transactions should be easy globally\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: transactions should be easy globally\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. AWS IAM  | Category: Security  | Score: 0.100\n",
            "  2. AWS Fargate  | Category: Compute  | Score: 0.090\n",
            "  3. Elastic Beanstalk  | Category: Compute  | Score: 0.083\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n",
            "Your choice [1-3 or Enter]: 1\n",
            "\n",
            "âœ… You selected option 1.\n",
            "=============== FINAL RECOMMENDATION ===============\n",
            "ðŸ·ï¸  AWS Service: AWS IAM\n",
            "ðŸ“‚ Category: Security\n",
            "ðŸ“Š Confidence Score (model space): 0.100\n",
            "ðŸ¤– Model Source: DistilBERT\n",
            "====================================================\n",
            "\n",
            "Your Query: sql data\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: sql data\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. Amazon ElastiCache  | Category: Database  | Score: 0.312\n",
            "  2. Amazon RDS  | Category: Database  | Score: 0.207\n",
            "  3. Amazon DynamoDB  | Category: Database  | Score: 0.094\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n",
            "Your choice [1-3 or Enter]: 1\n",
            "\n",
            "âœ… You selected option 1.\n",
            "=============== FINAL RECOMMENDATION ===============\n",
            "ðŸ·ï¸  AWS Service: Amazon ElastiCache\n",
            "ðŸ“‚ Category: Database\n",
            "ðŸ“Š Confidence Score (model space): 0.312\n",
            "ðŸ¤– Model Source: DistilBERT\n",
            "====================================================\n",
            "\n",
            "Your Query: storgae for fast task to speed up task\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: storgae for fast task to speed up task\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. Elastic Load Balancing  | Category: Networking  | Score: 0.201\n",
            "  2. AWS Lambda  | Category: Compute  | Score: 0.118\n",
            "  3. Amazon EBS  | Category: Storage  | Score: 0.116\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n",
            "Your choice [1-3 or Enter]: sort for fast computation\n",
            "No manual choice entered. Using top-ranked service.\n",
            "\n",
            "=============== FINAL RECOMMENDATION ===============\n",
            "ðŸ·ï¸  AWS Service: Elastic Load Balancing\n",
            "ðŸ“‚ Category: Networking\n",
            "ðŸ“Š Confidence Score (model space): 0.201\n",
            "ðŸ¤– Model Source: DistilBERT\n",
            "====================================================\n",
            "\n",
            "Your Query: storgae for fast computimg\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: storgae for fast computimg\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. Amazon Aurora  | Category: Database  | Score: 0.163\n",
            "  2. Elastic Load Balancing  | Category: Networking  | Score: 0.120\n",
            "  3. Elastic Beanstalk  | Category: Compute  | Score: 0.088\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n",
            "Your choice [1-3 or Enter]: 1\n",
            "\n",
            "âœ… You selected option 1.\n",
            "=============== FINAL RECOMMENDATION ===============\n",
            "ðŸ·ï¸  AWS Service: Amazon Aurora\n",
            "ðŸ“‚ Category: Database\n",
            "ðŸ“Š Confidence Score (model space): 0.163\n",
            "ðŸ¤– Model Source: DistilBERT\n",
            "====================================================\n",
            "\n",
            "Your Query: strofgae volumes\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: strofgae volumes\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. Amazon Aurora  | Category: Database  | Score: 0.091\n",
            "  2. Elastic Beanstalk  | Category: Compute  | Score: 0.069\n",
            "  3. Amazon DynamoDB  | Category: Database  | Score: 0.069\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n",
            "Your choice [1-3 or Enter]: key management\n",
            "No manual choice entered. Using top-ranked service.\n",
            "\n",
            "=============== FINAL RECOMMENDATION ===============\n",
            "ðŸ·ï¸  AWS Service: Amazon Aurora\n",
            "ðŸ“‚ Category: Database\n",
            "ðŸ“Š Confidence Score (model space): 0.091\n",
            "ðŸ¤– Model Source: DistilBERT\n",
            "====================================================\n",
            "\n",
            "Your Query: key management\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: key management\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. AWS KMS  | Category: Security  | Score: 0.448\n",
            "  2. Elastic Beanstalk  | Category: Compute  | Score: 0.046\n",
            "  3. AWS Secrets Manager  | Category: Security  | Score: 0.042\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n",
            "Your choice [1-3 or Enter]: 1\n",
            "\n",
            "âœ… You selected option 1.\n",
            "=============== FINAL RECOMMENDATION ===============\n",
            "ðŸ·ï¸  AWS Service: AWS KMS\n",
            "ðŸ“‚ Category: Security\n",
            "ðŸ“Š Confidence Score (model space): 0.448\n",
            "ðŸ¤– Model Source: DistilBERT\n",
            "====================================================\n",
            "\n",
            "Your Query:  archive centic operations\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: archive centic operations\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. Amazon DynamoDB  | Category: Database  | Score: 0.156\n",
            "  2. Amazon EBS  | Category: Storage  | Score: 0.136\n",
            "  3. Amazon EFS  | Category: Storage  | Score: 0.076\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n",
            "Your choice [1-3 or Enter]: 1\n",
            "\n",
            "âœ… You selected option 1.\n",
            "=============== FINAL RECOMMENDATION ===============\n",
            "ðŸ·ï¸  AWS Service: Amazon DynamoDB\n",
            "ðŸ“‚ Category: Database\n",
            "ðŸ“Š Confidence Score (model space): 0.156\n",
            "ðŸ¤– Model Source: DistilBERT\n",
            "====================================================\n",
            "\n",
            "Your Query: archive centric operations\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: archive centric operations\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. Amazon EBS  | Category: Storage  | Score: 0.124\n",
            "  2. Amazon DynamoDB  | Category: Database  | Score: 0.121\n",
            "  3. Amazon S3  | Category: Storage  | Score: 0.101\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n",
            "Your choice [1-3 or Enter]: 1\n",
            "\n",
            "âœ… You selected option 1.\n",
            "=============== FINAL RECOMMENDATION ===============\n",
            "ðŸ·ï¸  AWS Service: Amazon EBS\n",
            "ðŸ“‚ Category: Storage\n",
            "ðŸ“Š Confidence Score (model space): 0.124\n",
            "ðŸ¤– Model Source: DistilBERT\n",
            "====================================================\n",
            "\n",
            "Your Query: hard coded keys\n",
            "\n",
            "-----------------------------------------------\n",
            "ðŸ” User Query: hard coded keys\n",
            "ðŸ¤– Primary Model Used: DistilBERT\n",
            "\n",
            "Top candidate services (ranked):\n",
            "  1. AWS KMS  | Category: Security  | Score: 0.428\n",
            "  2. AWS Secrets Manager  | Category: Security  | Score: 0.069\n",
            "  3. Amazon ElastiCache  | Category: Database  | Score: 0.068\n",
            "\n",
            "By default, the system will pick option 1.\n",
            "If you want to override and choose a sub-service yourself,\n",
            "enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2217780697.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m     \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your choice [1-3 or Enter]: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mselected_service\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_service\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# HYBRID AWS ARCHITECTURAL RECOMMENDER\n",
        "# ML (TF-IDF) + DistilBERT + Top-k Ranking & Subcategory Choice\n",
        "# ================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import joblib\n",
        "from typing import Tuple, List\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Torch / Transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    DistilBertForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ================================\n",
        "# LOAD DATASET + SERVICE CATEGORY MAP\n",
        "# ================================\n",
        "\n",
        "# Load full CSV (with service_category etc.)\n",
        "df_full = pd.read_csv(\"aws_architectural_recommender_dataset_11000.csv\")\n",
        "print(\"Original shape:\", df_full.shape)\n",
        "print(\"Columns:\", df_full.columns.tolist())\n",
        "\n",
        "# Build service -> category mapping using ALL services present in dataset\n",
        "service_category_map = (\n",
        "    df_full[[\"primary_service\", \"service_category\"]]\n",
        "    .dropna()\n",
        "    .drop_duplicates()\n",
        "    .set_index(\"primary_service\")[\"service_category\"]\n",
        "    .to_dict()\n",
        ")\n",
        "print(\"\\nService â†’ Category map (sample):\")\n",
        "for s, c in list(service_category_map.items())[:10]:\n",
        "    print(f\"  {s}  -->  {c}\")\n",
        "\n",
        "# Now keep only columns needed for training\n",
        "df = df_full[[\"requirement_text\", \"primary_service\"]].copy()\n",
        "\n",
        "# ================================\n",
        "# BASIC CLEANING\n",
        "# ================================\n",
        "\n",
        "df = df.dropna(subset=[\"requirement_text\", \"primary_service\"])\n",
        "df[\"requirement_text\"] = df[\"requirement_text\"].astype(str).str.strip()\n",
        "df[\"primary_service\"] = df[\"primary_service\"].astype(str).str.strip()\n",
        "\n",
        "df = df[df[\"requirement_text\"].astype(bool)]\n",
        "df = df[df[\"primary_service\"].astype(bool)]\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"\\nAfter cleaning:\", df.shape)\n",
        "df.head()\n",
        "\n",
        "def preprocess(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "df[\"clean_text\"] = df[\"requirement_text\"].apply(preprocess)\n",
        "df = df[df[\"clean_text\"].astype(bool)].reset_index(drop=True)\n",
        "\n",
        "print(\"After preprocessing:\", df.shape)\n",
        "\n",
        "# ================================\n",
        "# SPLIT DATA\n",
        "# ================================\n",
        "\n",
        "X = df[\"clean_text\"]\n",
        "y = df[\"primary_service\"]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_ids = label_encoder.fit_transform(y)\n",
        "num_labels = len(label_encoder.classes_)\n",
        "print(\"Number of classes:\", num_labels)\n",
        "print(\"Classes (sample):\", list(label_encoder.classes_)[:10], \"...\")\n",
        "\n",
        "# 70% train, 30% temp\n",
        "X_train, X_temp, y_train_ids, y_temp_ids = train_test_split(\n",
        "    X,\n",
        "    y_ids,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y_ids\n",
        ")\n",
        "\n",
        "# 15% val, 15% test\n",
        "X_val, X_test, y_val_ids, y_test_ids = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp_ids,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=y_temp_ids\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Val size:\", len(X_val))\n",
        "print(\"Test size:\", len(X_test))\n",
        "\n",
        "y_train_str = label_encoder.inverse_transform(y_train_ids)\n",
        "y_val_str   = label_encoder.inverse_transform(y_val_ids)\n",
        "y_test_str  = label_encoder.inverse_transform(y_test_ids)\n",
        "\n",
        "# ================================\n",
        "# TF-IDF + ML MODELS\n",
        "# ================================\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=7000,\n",
        "    ngram_range=(1, 2),\n",
        "    sublinear_tf=True,\n",
        ")\n",
        "\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_val_vec   = vectorizer.transform(X_val)\n",
        "X_test_vec  = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF shapes:\", X_train_vec.shape, X_val_vec.shape, X_test_vec.shape)\n",
        "\n",
        "ml_models = {\n",
        "    \"LinearSVC\": LinearSVC(),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=5000, n_jobs=-1),\n",
        "    \"MultinomialNB\": MultinomialNB(),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=400, random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "}\n",
        "\n",
        "ml_results = {}\n",
        "\n",
        "for name, model in ml_models.items():\n",
        "    print(f\"\\nTraining ML model: {name}\")\n",
        "    model.fit(X_train_vec, y_train_str)\n",
        "    y_pred = model.predict(X_val_vec)\n",
        "\n",
        "    acc = accuracy_score(y_val_str, y_pred)\n",
        "    f1  = f1_score(y_val_str, y_pred, average=\"weighted\")\n",
        "\n",
        "    ml_results[name] = (acc, f1)\n",
        "    print(f\"{name} Val Accuracy: {acc:.4f}\")\n",
        "    print(f\"{name} Val F1-score: {f1:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "ml_results_df = pd.DataFrame(ml_results, index=[\"Accuracy\", \"F1\"]).T\n",
        "ml_results_df.sort_values(\"F1\", ascending=False, inplace=True)\n",
        "print(\"\\nML validation leaderboard:\\n\", ml_results_df)\n",
        "\n",
        "best_ml_name = ml_results_df[\"F1\"].idxmax()\n",
        "best_ml_model = ml_models[best_ml_name]\n",
        "print(f\"\\nBest ML model (val): {best_ml_name}\")\n",
        "\n",
        "# Retrain best model on train+val\n",
        "X_train_val_vec = vectorizer.fit_transform(pd.concat([X_train, X_val]))\n",
        "y_train_val_str = np.concatenate([y_train_str, y_val_str])\n",
        "\n",
        "best_ml_model.fit(X_train_val_vec, y_train_val_str)\n",
        "\n",
        "# Save artifacts\n",
        "joblib.dump(best_ml_model, \"best_aws_classifier.pkl\")\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
        "\n",
        "print(\"Saved: best_aws_classifier.pkl, tfidf_vectorizer.pkl, label_encoder.pkl\")\n",
        "\n",
        "# Test\n",
        "X_test_vec_final = vectorizer.transform(X_test)\n",
        "y_test_pred_ml = best_ml_model.predict(X_test_vec_final)\n",
        "\n",
        "ml_test_acc = accuracy_score(y_test_str, y_test_pred_ml)\n",
        "ml_test_f1  = f1_score(y_test_str, y_test_pred_ml, average=\"weighted\")\n",
        "\n",
        "print(\"\\n=== Best ML Model Test Performance ===\")\n",
        "print(\"Accuracy:\", ml_test_acc)\n",
        "print(\"Weighted F1:\", ml_test_f1)\n",
        "print(\"\\nClassification Report (ML):\\n\")\n",
        "print(classification_report(y_test_str, y_test_pred_ml))\n",
        "\n",
        "# ================================\n",
        "# DISTILBERT DATASETS\n",
        "# ================================\n",
        "\n",
        "df_bert = df[[\"requirement_text\", \"primary_service\"]].copy()\n",
        "df_bert[\"label_id\"] = label_encoder.transform(df_bert[\"primary_service\"])\n",
        "\n",
        "train_mask = df[\"clean_text\"].isin(X_train)\n",
        "val_mask   = df[\"clean_text\"].isin(X_val)\n",
        "test_mask  = df[\"clean_text\"].isin(X_test)\n",
        "\n",
        "bert_train = df_bert[train_mask].reset_index(drop=True)\n",
        "bert_val   = df_bert[val_mask].reset_index(drop=True)\n",
        "bert_test  = df_bert[test_mask].reset_index(drop=True)\n",
        "\n",
        "print(\"\\nBERT Train size:\", bert_train.shape)\n",
        "print(\"BERT Val size:\", bert_val.shape)\n",
        "print(\"BERT Test size:\", bert_test.shape)\n",
        "\n",
        "class AWSDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = list(texts)\n",
        "        self.labels = list(labels)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text  = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "train_dataset = AWSDataset(\n",
        "    texts=bert_train[\"requirement_text\"],\n",
        "    labels=bert_train[\"label_id\"],\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=128\n",
        ")\n",
        "val_dataset = AWSDataset(\n",
        "    texts=bert_val[\"requirement_text\"],\n",
        "    labels=bert_val[\"label_id\"],\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=128\n",
        ")\n",
        "test_dataset = AWSDataset(\n",
        "    texts=bert_test[\"requirement_text\"],\n",
        "    labels=bert_test[\"label_id\"],\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=128\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ================================\n",
        "# DISTILBERT TRAINING\n",
        "# ================================\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        "    id2label={i: l for i, l in enumerate(label_encoder.classes_)},\n",
        "    label2id={l: i for i, l in enumerate(label_encoder.classes_)},\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "EPOCHS = 5\n",
        "LR = 2e-5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LR)\n",
        "total_steps = len(train_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1 * total_steps),\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "def train_one_epoch(epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids      = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total   += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    acc = correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Train Loss: {avg_loss:.4f} | Train Acc: {acc:.4f}\")\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def eval_one_epoch():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids      = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            total_loss += loss.item() * input_ids.size(0)\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total   += labels.size(0)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    acc = correct / total\n",
        "    f1  = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "    print(f\"Val Loss: {avg_loss:.4f} | Val Acc: {acc:.4f} | Val F1: {f1:.4f}\")\n",
        "    return avg_loss, acc, f1\n",
        "\n",
        "best_val_f1 = 0.0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\n===== Epoch {epoch+1}/{EPOCHS} =====\")\n",
        "    train_one_epoch(epoch)\n",
        "    val_loss, val_acc, val_f1 = eval_one_epoch()\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        print(\"New best DistilBERT model, saving checkpoint...\")\n",
        "        model.save_pretrained(\"distilbert_aws_model\")\n",
        "        tokenizer.save_pretrained(\"distilbert_aws_model\")\n",
        "\n",
        "# ================================\n",
        "# TEST DISTILBERT\n",
        "# ================================\n",
        "\n",
        "best_bert_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert_aws_model\")\n",
        "best_bert_model.to(device)\n",
        "best_bert_model.eval()\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids      = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = best_bert_model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "bert_test_acc = accuracy_score(all_labels, all_preds)\n",
        "bert_test_f1  = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "\n",
        "print(\"\\n=== DistilBERT Test Performance ===\")\n",
        "print(\"Accuracy:\", bert_test_acc)\n",
        "print(\"Weighted F1:\", bert_test_f1)\n",
        "print(\"\\nClassification Report (DistilBERT):\\n\")\n",
        "print(classification_report(\n",
        "    [label_encoder.classes_[i] for i in all_labels],\n",
        "    [label_encoder.classes_[i] for i in all_preds]\n",
        "))\n",
        "\n",
        "# ================================\n",
        "# HYBRID + TOP-K RANKING\n",
        "# ================================\n",
        "\n",
        "ml_model = joblib.load(\"best_aws_classifier.pkl\")\n",
        "tfidf    = joblib.load(\"tfidf_vectorizer.pkl\")\n",
        "le       = joblib.load(\"label_encoder.pkl\")\n",
        "\n",
        "bert_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert_aws_model\").to(device)\n",
        "bert_tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert_aws_model\")\n",
        "bert_model.eval()\n",
        "\n",
        "def ml_topk(text: str, k: int = 3) -> List[Tuple[str, float]]:\n",
        "    \"\"\"\n",
        "    Return top-k (service, score) from the ML model.\n",
        "    \"\"\"\n",
        "    clean = preprocess(text)\n",
        "    if not clean:\n",
        "        return []\n",
        "\n",
        "    vec = tfidf.transform([clean])\n",
        "\n",
        "    if hasattr(ml_model, \"predict_proba\"):\n",
        "        proba = ml_model.predict_proba(vec)[0]\n",
        "        classes = ml_model.classes_\n",
        "        idx_sorted = np.argsort(proba)[::-1][:k]\n",
        "        return [(classes[i], float(proba[i])) for i in idx_sorted]\n",
        "\n",
        "    elif hasattr(ml_model, \"decision_function\"):\n",
        "        scores = ml_model.decision_function(vec)\n",
        "        if scores.ndim == 1:\n",
        "            scores = scores.reshape(1, -1)\n",
        "        scores = scores[0]\n",
        "        exp_scores = np.exp(scores - scores.max())\n",
        "        proba = exp_scores / exp_scores.sum()\n",
        "        classes = ml_model.classes_\n",
        "        idx_sorted = np.argsort(proba)[::-1][:k]\n",
        "        return [(classes[i], float(proba[i])) for i in idx_sorted]\n",
        "\n",
        "    else:\n",
        "        label = ml_model.predict(vec)[0]\n",
        "        return [(label, 0.5)]\n",
        "\n",
        "def distilbert_topk(text: str, k: int = 3) -> List[Tuple[str, float]]:\n",
        "    \"\"\"\n",
        "    Return top-k (service, score) from DistilBERT.\n",
        "    \"\"\"\n",
        "    enc = bert_tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    ids  = enc[\"input_ids\"].to(device)\n",
        "    mask = enc[\"attention_mask\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = bert_model(input_ids=ids, attention_mask=mask)\n",
        "        logits = out.logits[0].cpu().numpy()\n",
        "\n",
        "    exp_logits = np.exp(logits - logits.max())\n",
        "    proba = exp_logits / exp_logits.sum()\n",
        "\n",
        "    idx_sorted = np.argsort(proba)[::-1][:k]\n",
        "    return [(le.classes_[i], float(proba[i])) for i in idx_sorted]\n",
        "\n",
        "def hybrid_recommend_with_ranking(\n",
        "    text: str,\n",
        "    ml_threshold: float = 0.75,\n",
        "    top_k: int = 3\n",
        ") -> Tuple[str, str, float, List[Tuple[str, str, float]]]:\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        best_service, source_model, best_score,\n",
        "        ranked_candidates = [(service, category, score), ...]\n",
        "    \"\"\"\n",
        "    ml_candidates = ml_topk(text, k=top_k)\n",
        "\n",
        "    if len(ml_candidates) == 0:\n",
        "        # Fallback to DistilBERT only\n",
        "        bert_candidates = distilbert_topk(text, k=top_k)\n",
        "        ranked = [\n",
        "            (svc, service_category_map.get(svc, \"Unknown\"), score)\n",
        "            for svc, score in bert_candidates\n",
        "        ]\n",
        "        best_service, _, best_score = ranked[0]\n",
        "        return best_service, \"DistilBERT\", best_score, ranked\n",
        "\n",
        "    best_ml_service, best_ml_score = ml_candidates[0]\n",
        "\n",
        "    if best_ml_score >= ml_threshold:\n",
        "        source = \"ML\"\n",
        "        raw_candidates = ml_candidates\n",
        "    else:\n",
        "        source = \"DistilBERT\"\n",
        "        raw_candidates = distilbert_topk(text, k=top_k)\n",
        "\n",
        "    ranked = [\n",
        "        (svc, service_category_map.get(svc, \"Unknown\"), score)\n",
        "        for svc, score in raw_candidates\n",
        "    ]\n",
        "\n",
        "    best_service, _, best_score = ranked[0]\n",
        "    return best_service, source, best_score, ranked\n",
        "\n",
        "def hybrid_recommend_aws_service(text: str, ml_threshold: float = 0.75) -> Tuple[str, str, float]:\n",
        "    \"\"\"\n",
        "    Backward-compatible function (for Gradio, etc.)\n",
        "    Returns single best service + source + best_score.\n",
        "    \"\"\"\n",
        "    best_service, source, best_score, _ = hybrid_recommend_with_ranking(\n",
        "        text, ml_threshold=ml_threshold, top_k=3\n",
        "    )\n",
        "    return best_service, source, best_score\n",
        "\n",
        "# ================================\n",
        "# INTERACTIVE CLI WITH SUBCATEGORY CHOICE\n",
        "# ================================\n",
        "\n",
        "print(\"\\n================ AWS ARCHITECTURAL RECOMMENDER â€” INTERACTIVE MODE ================\")\n",
        "print(\"Type your AWS requirement below. Type 'exit' to stop.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_text = input(\"Your Query: \").strip()\n",
        "\n",
        "    if user_text.lower() == \"exit\":\n",
        "        print(\"\\nExiting AWS Recommender System. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    if len(user_text) < 3:\n",
        "        print(\"âš ï¸ Please enter a valid requirement (at least 3 characters).\\n\")\n",
        "        continue\n",
        "\n",
        "    best_service, source, best_score, ranked_list = hybrid_recommend_with_ranking(\n",
        "        user_text,\n",
        "        ml_threshold=0.75,\n",
        "        top_k=3\n",
        "    )\n",
        "\n",
        "    print(\"\\n-----------------------------------------------\")\n",
        "    print(f\"ðŸ” User Query: {user_text}\")\n",
        "    print(f\"ðŸ¤– Primary Model Used: {source}\")\n",
        "    print(\"\\nTop candidate services (ranked):\")\n",
        "\n",
        "    for idx, (svc, cat, score) in enumerate(ranked_list, start=1):\n",
        "        print(f\"  {idx}. {svc}  | Category: {cat}  | Score: {score:.3f}\")\n",
        "\n",
        "    print(\"\\nBy default, the system will pick option 1.\")\n",
        "    print(\"If you want to override and choose a sub-service yourself,\")\n",
        "    print(\"enter 1 / 2 / 3 (depending on how many are shown), or press Enter to accept #1.\")\n",
        "\n",
        "    choice = input(\"Your choice [1-3 or Enter]: \").strip()\n",
        "\n",
        "    selected_service = best_service\n",
        "    selected_category = service_category_map.get(best_service, \"Unknown\")\n",
        "\n",
        "    if choice.isdigit():\n",
        "        idx = int(choice)\n",
        "        if 1 <= idx <= len(ranked_list):\n",
        "            selected_service, selected_category, selected_score = ranked_list[idx - 1]\n",
        "            print(f\"\\nâœ… You selected option {idx}.\")\n",
        "            best_score = selected_score  # update to user-selected score\n",
        "        else:\n",
        "            print(\"Invalid choice, falling back to top-ranked service.\\n\")\n",
        "    else:\n",
        "        print(\"No manual choice entered. Using top-ranked service.\\n\")\n",
        "\n",
        "    print(\"=============== FINAL RECOMMENDATION ===============\")\n",
        "    print(f\"ðŸ·ï¸  AWS Service: {selected_service}\")\n",
        "    print(f\"ðŸ“‚ Category: {selected_category}\")\n",
        "    print(f\"ðŸ“Š Confidence Score (model space): {best_score:.3f}\")\n",
        "    print(f\"ðŸ¤– Model Source: {source}\")\n",
        "    print(\"====================================================\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHwcBF2fRprV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d54a9dce5f342439f9f29bdec8af974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f40d7a1c4c5d430e9070ef9c3a356c19",
              "IPY_MODEL_a2a5ed36e8c64e37a14c8898c02a2235",
              "IPY_MODEL_0f244e19e3d643e09880d3facb11609e"
            ],
            "layout": "IPY_MODEL_2a5485dc811c4cb3a5f26ca8333d07f7"
          }
        },
        "f40d7a1c4c5d430e9070ef9c3a356c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa11a4d2fa0640f3879dd1852bddf4ef",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d36b556aba1e48ccb865785d0cafcf57",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "a2a5ed36e8c64e37a14c8898c02a2235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_783c4a2068184bc9b1e51bcf8b5738d2",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abef25ba988a4ea690f214727efe917d",
            "value": 267954768
          }
        },
        "0f244e19e3d643e09880d3facb11609e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e30e0195bbb48ed8be66d504a2d259f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5fdf2cb8df8c4b7c8a3fc4d23b206ce3",
            "value": "â€‡268M/268Mâ€‡[01:33&lt;00:00,â€‡2.65MB/s]"
          }
        },
        "2a5485dc811c4cb3a5f26ca8333d07f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa11a4d2fa0640f3879dd1852bddf4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36b556aba1e48ccb865785d0cafcf57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "783c4a2068184bc9b1e51bcf8b5738d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abef25ba988a4ea690f214727efe917d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e30e0195bbb48ed8be66d504a2d259f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fdf2cb8df8c4b7c8a3fc4d23b206ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}